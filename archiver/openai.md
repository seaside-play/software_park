原文[OpenAI 提出开源 Triton 语言作为 Nvidia CUDA 的替代方案](https://www.7claw.com/57320.html)

# OpenAI 提出开源 Triton 语言作为 Nvidia CUDA 的替代方案

根据人工智能研究公司 OpenAI 的说法，Nvidia 的图形处理单元太难编程，包括使用 Nvidia 自己的编程工具 CUDA。

Triton“适用于尽管拥有良好的软件工程技能但不熟悉 GPU 编程的机器学习研究人员和工程师，”Tillet 说。

该语言来自 OpenAI，它开发了风靡全球的 GPT-3 自然语言处理程序，这一事实可能会使该代码在 AI 领域更加卓越。

该软件以开源形式提供，要求在代码的大量副本的任何分发中包含版权声明和许可。

最初的 Triton 揭幕发生在 Tillet 于 2019 年发表的一篇论文中，当时他还是哈佛大学的一名研究生，还有他的导师 H. T. Kung 和 David Cox。

Tillet 着手解决的问题是如何制作一种比供应商特定的 AI 库（例如 Nvidia 的 cuDNN）更具表现力的语言，这意味着能够处理神经网络中涉及的矩阵的各种操作； 同时具有可移植性，并具有可与 cuDNN 和类似供应商库相媲美的性能。

## 欠缺
- “GPU 在优化局部性和并行性方面仍然极具挑战性”。

## Triton优势
Triton 的语义将图块指定为内置类型，这样 Triton 编译器就可以搞清楚这些片段如何在 GPU 的许多核心及其伴随的寄存器中有效分配。

实际上，并行化和优化代码的工作已从语言下推到编译器中。

正如 Tillet 所说，编译器“自动执行各种重要的程序优化”。

周三的博文没有强调性能指标，只是说 **Triton** 可以与 **CuBLAS** 匹敌。 然而，在 Tillet 的原始论文中，该语言的 **Triton-C** 版本在运行所谓的深度卷积时能够获得比 Nvidia 的 **CuDNN** 库更好的性能，深度卷积是将输入视为局部相关数据组的操作，例如图像 像素。


CuBLAS是CUDA平台中的一个重要的加速库，专注于基本的线性代数运算。它是一个传统线性代数库的接口，即基本线性代数子程序库（BLAS）。CuBLAS利用针对NVIDIA GPU高度优化的插入式行业标准BLAS API，加速AI和HPC应用。

CuBLAS提供了一套高效的矩阵运算函数，如矩阵乘法、矩阵向量乘法、矩阵转置等。它包含两套API，一套是用户需要自行分配GPU内存空间并按照规定格式填入数据的cuBLAS API，另一套是可以在CPU端分配数据并自动管理内存、执行计算的cuBLASXT API。

此外，CuBLAS还提供了用于批量运算、跨多个GPU的执行以及混合精度和低精度执行的扩展程序。通过使用CuBLAS，应用将能自动从定期性能提升及新的GPU体系架构中受益。

总的来说，CuBLAS是一个功能强大且高效的线性代数运算库，充分利用了GPU的并行计算能力，为大规模的数值计算和科学计算任务提供了高性能的线性代数运算接口。

可以想象，Triton 可能是竞争对手为其芯片获得广泛的开源平台所需的新软件工具之一